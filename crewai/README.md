# CrewAI and Llama Stack

**i. Installation and Configuration**

Refer to the [Installation and Configuration](../README.md#installation-and-configuration) section for instructions on running a Llama Stack instance with the required providers.

**ii. Run the Sample Code**

We have provided an example client under the src directory that connects to a local Llama Stack instance. Navigate to the crewai directory and use the following command to test the connection:

```
uv run python src/client.py
```